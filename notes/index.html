<!DOCTYPE html>
<html lang="en-AU">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width,initial-scale=1" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="twitter:card" content="summary_large_image" />
        <meta name="twitter:creator" content="" />
        <meta name="twitter:title" content="" />
        <meta name="twitter:description" content="" />
        <meta name="twitter:image:src" content="" />
        <meta property="og:url" content="" />
        <meta property="og:image" content="" />
        <meta property="og:title" content="" />
        <meta property="og:description" content="" />
        <title>We Are What We Steal - Notes.</title>
        <link rel="stylesheet" href="../css/under-shirt.css" />
        <link rel="dns-prefetch" href="https://d3js.org/" />
        <link rel="shortcut icon" href="../img/icon.png" type="image/png" />
    </head>
    <body id="notes">
        <header>
            <div class="icon">
                <div>first reported stolen <a href="https://trove.nla.gov.au/newspaper/article/252046578?searchTerm=%22sheep%22">May, 1862</a></div>
            </div>

            <h1>We Are What We Steal</h1>

            <nav>
                <a href="../">Intro</a>
                <a href="../people/">People</a>
                <a href="../places/">Places</a>
                <a href="../things/">Things</a>
                <a href="../notes/">Notes</a>
            </nav>
            
        </header>

        <main>
            <h2 data-count="v">Notes</h2>

            <div class="lrg">
                <img src="../img/gazette.jpg" alt="Part of a page from the library's earliest issue">
                <p class="note">From the library's earliest issue (#45), Monday 4th of June, 1860. <a href="https://trove.nla.gov.au/newspaper/page/27938048">View on Trove</a> →</p>
            </div>


            <div class="cols">
                <div class="a">
                    <p>
                        Using n-grams has a number of potential issues and limitations, and as an approach is obviously an oversimplification, so it won't reveal <em>all</em> the changes that occurred, but it can provide an interesting
                        overview of the period, and highlight some of the more pronounced trends. For example, it relies on the text being correct, and given the gazette has been converted from the original documents via optical character
                        recognition (OCR), like many OCR datasets (especially those of older documents with weathered paper) there's errors in the conversion ('side-lovers' for 'side-levers', 'dork' for 'dark etc), that will effect the
                        final result to varying degrees.
                    </p>

                    <p>
                        As mentioned earlier, the gazette also repeats a number of entries, as well as includes occasional supplements from other gazettes. Initially I was going to try and exclude all of that, but given the size and scale
                        (and variety) of the article formats, in the end I was more worried that by attempting to exclude the repeats and supplements, unless I was 100% accurate, I might accidentally introduce more bias than if I just used
                        the entire corpus as is. The same concern was there with the typos introduced by OCR: if I included some common OCR errors but missed others, this would then weight the terms incorrectly. (In looking for terms I'd
                        use Trove to get an idea of any different spellings over the period - 'grey' vs 'gray', 'color' vs 'colour' etc - but was mainly looking at how it related to hyphens and/or capital letters, such as 'Blucher boots' vs
                        'blucher-boots', rather than trying to capture all possible misspellings...)
                        <!-- mustache vs moustache? nickle vs nickle? grey vs gray? -->
                    </p>

                    <p>
                        There was a similar issue with homonyms, especially with the section on places. For example, was 'Albert' in the text referring to a person named Albert, or the town called Albert, or The Royal Albert Hotel, or an
                        Albert chain. Obviously there are ways to disambiguate this on a case by case basis, an/or use some form of Part-Of-Speech tagger to classify each occurrence, but in the end I just decided to work with the text as
                        is.
                    </p>
                </div>

                <div class="b">
                    <p>
                        Therefore results should still be taken with a grain of salt, as what they may appear to show is open to misinterpretation. For example consider the trends for the two terms 'grey' and 'slaughter-house' below. As you
                        can see, 'grey' drops to almost nothing after 1869, and 'slaughter-house' in 1885. However this does not mean that there was no grey hair or grey trousers in NSW after 1869, or that slaughter-houses suddenly all
                        closed in 1885. Rather that the gazette switched to using 'gray' instead of 'grey' in the case of the former, and it no longer reported the names of those appointed as inspectors of slaughter-houses in the case of
                        the latter.
                    </p>

                    <div class="inline" data-term="grey"></div>
                    <div class="inline" data-term="slaughter-house"></div>

                    <p>
                        Finally, given the size and scale of the corpus (almost 20 million words), and the number of terms analysed and counted, there's also likely to be a variety of errors in my code. Some will probably be to do with the
                        regex I've used to extract the terms, so for the sake of transparency you can see what's been used for by hovering over/clicking the text. Despite all these issues however, the n-gram/bag-of-words approach is a good
                        way of quickly getting a sense of the overall terms and trends in a large body of data.
                    </p>
                </div>
            </div>

            <div class="quote">
                <em>Issue #37</em>
                <div class="blockquote-wrapper">
                    <blockquote>
                        ...about 17 years of age, <span data-term="thin features" data-loc="TR">thin features</span>, short hair, rather deaf, supposed to have the stolen <span data-term="dress" data-loc="BL">dress</span> on, she has
                        an aunt living at <span data-term="Balmain" data-loc="BR">Balmain</span>, who keeps a butcher's shop
                    </blockquote>
                    <div class="details">
                        <p>Sydney, November 1862</p>
                        <p><a href="https://trove.nla.gov.au/newspaper/article/252046969"></a></p>
                    </div>
                </div>
            </div>

            <h3>Rough Methodology</h3>

            <div class="cols">
                <div class="a">
                    <p>This is just a quick overview of the main steps involved in the process (and was all done just using javascript 'cos that's all I know...).</p>
                    <ol>
                        <li>
                            Download the gazette data from <a href="https://trove.nla.gov.au/">Trove</a> (and thanks to <a href="https://twitter.com/wragge">@wragge</a> for the
                            <a href="https://troveconsole.herokuapp.com/">Trove API Console</a> for helping me work out the requests to make)
                        </li>

                        <li>Clean up the data (strip html tags, line-breaks, tabs, double spaces, stray characters etc)</li>

                        <li>Count words per year (just counted the spaces) in order to work out the rate of terms per year</li>

                        <li>
                            I then used regex to count the number of times a word or phrase appeared per year. With certain terms, I'd also include the plural version (e.g. ‘earring' and ‘earrings'), and/or variations with hyphens (e.g.
                            'public house' and 'public-house'), and/or case insensitive searches (e.g. SYDNEY and Sydney). To see what variations existed I'd use <a href="https://trove.nla.gov.au/search/advanced/category/newspapers?date.from=1860-01-01&date.to=1900-12-31&sortBy=dateAsc&l-advtitle=1476&keyword=%22public-house%22">Trove</a>, limited to the gazette from 1860-1900.
                        </li>

                        <li>I would then take the number of time the term appeared each year, and work out the rate, based on the number of words in that year.</li>

                        <li>
                            The results were then graphed. As the rates differs greatly, from only a handful of mentions per year to thousands, they're scaled against the highest rate for that term, in order to best see the differences over
                            time, so they are relative. The dotted line represents the absolute rate. i.e., every term on the page uses the same scale for the line, which is 400 mentions per 100,000 words in a year (for reference, 'gold' is mentioned ~800 times per 100,000 words)
                        </li>
                    </ol>
                </div>

                <div class="b">
                    <p>For the map section, the approach was slightly different:</p>
                    <ol>
                        <li>
                            I ran a list of all the places in NSW through the gazette to see what what was mentioned, and then ran that list through the gazette again to get the count. I used
                            <a href="https://www.geonames.org">geonames.org</a> for the names and locations, which lists its data providers as Geoscience Australia and the ABS among others. It (understandably) doesn't include historical
                            suburbs, plus the spelling of some place names have changed, so certain places may have been missed.
                        </li>

                        <li>Because this deals with the period when NSW was still a colony, the ACT obviously didn't exist, so I did the same process with ACT suburbs (but ignored all the ones that were named after politicians)</li>
                    </ol>

                    <p>For 'Selective Reporting':</p>
                    <ol>
                        <li>
                            I got all articles from the gazette that mentioned the words 'murder' and 'Aboriginal' (or variations, including '(Ab.)' which is what the gazette often used as an abbreviation from 1877). There were 145 entries in
                            the end.
                        </li>

                        <li>I then read the articles and if they were reports of a murder, classified them according to their alleged suspect(s) and victim(s)</li>
                    </ol>
                </div>
            </div>

            <div class="quote">
            <em>Issue #42</em>
            <div class="blockquote-wrapper">
                <blockquote>
                    ...suspected of stealing a <span data-term="saddle-cloth" data-loc="TR">saddle-cloth</span>... Cohen is about 30 years of age, black <span data-term="curly hair" data-loc="BR">curly hair</span>, long nose; a little lame; Jewish appearance; a native of <span data-term="the Colony" data-loc="BL">the Colony</span>. Supposed to have gone to Dubbo.
                </blockquote>
                <div class="details">
                    <p>Molong, October 1869</p>
                    <p><a href="https://trove.nla.gov.au/newspaper/article/252048728"></a></p>
                </div>
            </div>
        </div>


        </main>

        <a href="../" class="next">← INTRO</a>

        <footer>
            <nav>
                <a href="../">Intro</a>
                <a href="../people/">People</a>
                <a href="../places/">Places</a>
                <a href="../things/">Things</a>
                <a href="../notes/">Notes</a>
            </nav>

            <p>
                Thanks to <a href="https://www.sl.nsw.gov.au/">The State Library of NSW</a> and the team at <a href="https://dxlab.sl.nsw.gov.au/">DX Lab</a> for the opportunity to work on this project, and especially
                <a href="https://twitter.com/paulabray">Paula Bray</a> (also thanks to <a href="https://trove.nla.gov.au/">Trove</a>, an amazing resource...). <span>Project by Brett Tweedie</span>
            </p>

            <p class="logos">
                <a href="https://www.sl.nsw.gov.au/"><img src="../img/logo-slnsw.png" alt="State Library of NSW" /></a>
                <a href="https://dxlab.sl.nsw.gov.au/"><img src="../img/logo-dxlab.png" alt="DX LAB" /></a>
            </p>

            <div class="icon">
                <div>bottles of Cologne first<br> stolen <a href="https://trove.nla.gov.au/newspaper/article/252040712?searchTerm=%22cologne%22">August, 1864</a></div>
            </div>
        </footer>

        <div id="info"></div>

        <script src="https://d3js.org/d3.v5.min.js"></script>
        <script src="../data/terms-all.js"></script>
        <script src="../data/places.js"></script>
        <script src="../js/suspenders.js"></script>
    </body>
</html>
